{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ['JAVA_HOME'] = '/usr/lib/jvm/java-1.8.0-openjdk-1.8.0.312.b07-1.el7_9.x86_64'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyspark\n",
    "from pyspark.sql import *\n",
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Spark session.\n",
      "Spark session created.\n"
     ]
    }
   ],
   "source": [
    "print(\"Creating Spark session.\")\n",
    "configuation_properties = [\n",
    "    (\"spark.master\",\"local[95]\"),\n",
    "    (\"spark.ui.port\",\"4050\"),\n",
    "    (\"spark.executor.memory\",\"750g\"),\n",
    "    ('spark.driver.memory',  '2000g'),\n",
    "    (\"spark.driver.maxResultSize\", '0'), # unlimited\n",
    "    (\"spark.network.timeout\",            \"10000001\"),\n",
    "    (\"spark.executor.heartbeatInterval\", \"10000000\")\n",
    "    #(\"spark.dynamicAllocation.enabled\",\"true\"),\n",
    "    #(\"spark.shuffle.service.enabled\",\"true\"),\n",
    "]\n",
    "\n",
    "conf = SparkConf().setAll( configuation_properties )\n",
    "\n",
    "# create the context\n",
    "sc = pyspark.SparkContext(conf=conf)\n",
    "spark = SparkSession.builder.getOrCreate()\n",
    "\n",
    "# for logging temporarily\n",
    "# sc.setLogLevel('DEBUG')\n",
    "print(\"Spark session created.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "goal: simply get the most recent 6 months worth of posts and comments for /r/photocritique and save them separately for ease"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "SUBREDDIT = 'photocritique'\n",
    "# SUBREDDIT = 'AskReddit'\n",
    "\n",
    "OUTPUT_DIR =  '/projects/bdata/bdatasets/photocritique/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# posts_path = '/projects/bdata/moderation/pushshift/RS_*'\n",
    "# comments_path = '/projects/bdata/moderation/pushshift/RC_*'\n",
    "\n",
    "posts_path = '/projects/bdata/moderation/pushshift/RS_2021-*'\n",
    "comments_path = '/projects/bdata/moderation/pushshift/RC_2021-*'\n",
    "\n",
    "# posts_path = '/projects/bdata/moderation/pushshift/RS_2021-06'\n",
    "# comments_path = '/projects/bdata/moderation/pushshift/RC_2021-06'\n",
    "\n",
    "# posts_path = '/projects/bdata/moderation/pushshift/1000_posts_2019-06'\n",
    "# comments_path = '/projects/bdata/moderation/pushshift/1000_comments_2019-06'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "post_schema    = 'id STRING, subreddit STRING, author STRING, created_utc INTEGER, score INTEGER, title STRING, url STRING'\n",
    "comment_schema = 'id STRING, subreddit STRING, link_id STRING, author STRING, created_utc INTEGER, score INTEGER, body STRING'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading posts from /projects/bdata/moderation/pushshift/RS_2021-06.\n",
      "Finished loading posts in 0.028 minutes.\n"
     ]
    }
   ],
   "source": [
    "print('Starting loading posts from {}.'.format( posts_path ))\n",
    "start_time = time.monotonic()\n",
    "posts = spark.read.schema(post_schema).option(\"mode\", \"DROPMALFORMED\").json( posts_path )\n",
    "print(\"Finished loading posts in {:5.3f} minutes.\".format( (time.monotonic()-start_time)/60 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting loading comments from /projects/bdata/moderation/pushshift/RC_2021-06.\n",
      "Finished loading comments in 0.001 minutes.\n"
     ]
    }
   ],
   "source": [
    "print('Starting loading comments from {}.'.format( comments_path ))\n",
    "start_time = time.monotonic()\n",
    "comments = spark.read.schema(comment_schema).option(\"mode\", \"DROPMALFORMED\").json( comments_path )\n",
    "print(\"Finished loading comments in {:5.3f} minutes.\".format( (time.monotonic()-start_time)/60 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "posts    = posts.where(      posts.subreddit == SUBREDDIT)\n",
    "comments = comments.where(comments.subreddit == SUBREDDIT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting writing to /projects/bdata/bdatasets/photocritique/.\n",
      "Finished writing in 111.304 minutes.\n"
     ]
    }
   ],
   "source": [
    "print('Starting writing to {}.'.format( OUTPUT_DIR ))\n",
    "start_time = time.monotonic()\n",
    "posts.write.json(   OUTPUT_DIR+'posts_jan-jun_2021',    mode='overwrite')\n",
    "comments.write.json(OUTPUT_DIR+'comments_jan-jun_2021', mode='overwrite')\n",
    "print(\"Finished writing in {:5.3f} minutes.\".format( (time.monotonic()-start_time)/60 ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:pyspark]",
   "language": "python",
   "name": "conda-env-pyspark-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
